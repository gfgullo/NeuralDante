{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPdwRh/UGSZ18ujo/JGNBC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfgullo/NeuralDante/blob/main/neural_dante.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Dante"
      ],
      "metadata": {
        "id": "Omah1C4sWI_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scarichiamo il dataset"
      ],
      "metadata": {
        "id": "OfgLucShcrPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "H0aOqihhxrji"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3UX8XLcVNUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e904629b-df4a-4384-c7c4-806e9ed594fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-29 16:42:05--  https://dmf.unicatt.it/~della/pythoncourse18/commedia.txt\n",
            "Resolving dmf.unicatt.it (dmf.unicatt.it)... 185.11.152.34\n",
            "Connecting to dmf.unicatt.it (dmf.unicatt.it)|185.11.152.34|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 557962 (545K) [text/plain]\n",
            "Saving to: ‘commedia.txt.10’\n",
            "\n",
            "commedia.txt.10     100%[===================>] 544.88K   698KB/s    in 0.8s    \n",
            "\n",
            "2023-04-29 16:42:07 (698 KB/s) - ‘commedia.txt.10’ saved [557962/557962]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dmf.unicatt.it/~della/pythoncourse18/commedia.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importiamo i moduli"
      ],
      "metadata": {
        "id": "X9PQWyddcpl4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\""
      ],
      "metadata": {
        "id": "x-3wMSxsqjuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import spacy\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from random import randint\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "gpuec2JRYHrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download it_core_news_sm"
      ],
      "metadata": {
        "id": "iopeUpdOaiT2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3545c78-b02b-49f8-e5ef-ad6764bf3e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-29 16:46:47.622139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting it-core-news-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_sm-3.5.0/it_core_news_sm-3.5.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from it-core-news-sm==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->it-core-news-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('it_core_news_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"it_core_news_sm\")"
      ],
      "metadata": {
        "id": "VtxgFRcgaZ98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessiamo il testo"
      ],
      "metadata": {
        "id": "53aiB5WccuFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f = open(\"commedia.txt\", \"r\", encoding=\"utf-8\")\n",
        "commedia = f.read()\n",
        "commedia[:100]"
      ],
      "metadata": {
        "id": "Qa_9_3F3XWNI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4d0c8aaf-80b9-4ba7-e974-862f91561509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LA DIVINA COMMEDIA\\ndi Dante Alighieri\\nINFERNO\\n\\n\\n\\nInferno: Canto I\\n\\n  Nel mezzo del cammin di nostra '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace(\"'\",\" \").replace(\"\\n\",\" \")\n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        "  text = re.sub(' +', ' ', text)\n",
        "  return text"
      ],
      "metadata": {
        "id": "KK_w1SUca13u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "commedia = preprocessing_text(commedia)\n",
        "commedia[:500]"
      ],
      "metadata": {
        "id": "ZuIB50H3ZGjy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "0581be9a-900e-4de6-b7b4-68741d6b8285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'la divina commedia di dante alighieri inferno inferno canto i nel mezzo del cammin di nostra vita mi ritrovai per una selva oscura ché la diritta via era smarrita ahi quanto a dir qual era è cosa dura esta selva selvaggia e aspra e forte che nel pensier rinova la paura tant è amara che poco è più morte ma per trattar del ben ch i vi trovai dirò de l altre cose ch i v ho scorte io non so ben ridir com i v intrai tant era pien di sonno a quel punto che la verace via abbandonai ma poi ch i fui al p'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text):\n",
        "  tokens = nlp(text)\n",
        "  tokens_filtered = [token.text for token in tokens]\n",
        "  return tokens_filtered\n",
        "\n",
        "tokens = tokenize(commedia)"
      ],
      "metadata": {
        "id": "avb2p9c-bMJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens[:10]"
      ],
      "metadata": {
        "id": "RhHjfcYvbi9z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7fbeb86-cb6f-49f2-a29a-b5a6de2d9490"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['la',\n",
              " 'divina',\n",
              " 'commedia',\n",
              " 'di',\n",
              " 'dante',\n",
              " 'alighieri',\n",
              " 'inferno',\n",
              " 'inferno',\n",
              " 'canto',\n",
              " 'i']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 11\n",
        "\n",
        "sents = []\n",
        "\n",
        "for i in range(maxlen, len(tokens)):\n",
        "  sents.append(tokens[i-maxlen:i])"
      ],
      "metadata": {
        "id": "Xic_S6lQb-jU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sents)\n",
        "sents = tokenizer.texts_to_sequences(sents)\n",
        "sents[0]"
      ],
      "metadata": {
        "id": "mtYFBTxedUjW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfdc22b5-0b4d-4208-f580-129c44da95a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 350, 3582, 6, 2648, 3581, 248, 248, 106, 26, 41]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sents = np.array(sents)\n",
        "X = sents[:,:-1]\n",
        "y = sents[:,-1]"
      ],
      "metadata": {
        "id": "d83UNce4d-rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(tokenizer.word_docs)"
      ],
      "metadata": {
        "id": "fNfpCW44gD44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = to_categorical(y)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "wQ0mFCVNsqqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "883c285b-0c5e-4db2-92f0-135c1dd1fee5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101901, 12822)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creazione della rete ricorrente"
      ],
      "metadata": {
        "id": "PAY1BKdrhlBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size+1, maxlen-1, input_length=maxlen-1))\n",
        "model.add(LSTM(50, return_sequences=True))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(50, activation=\"relu\"))\n",
        "model.add(Dense(vocab_size+1, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "SdzI4zgghdNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=\"accuracy\")"
      ],
      "metadata": {
        "id": "KwlfMzXsjPgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "L04u8dNLjfHK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "452bba71-9362-4dc2-b167-952668589f66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 10, 10)            128220    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 10, 50)            12200     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                20200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 12822)             653922    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 817,092\n",
            "Trainable params: 817,092\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(seed=None, random_seed_length=10, generate_len=25):\n",
        "\n",
        "  output = \"\"\n",
        "\n",
        "  if seed is None:\n",
        "    start_index = randint(0, len(commedia))\n",
        "    text = commedia[start_index:start_index+random_seed_length]\n",
        "  else:\n",
        "    text = preprocessing_text(seed)\n",
        "\n",
        "  for i in range(generate_len):\n",
        "\n",
        "    tokens = np.array(tokenizer.texts_to_sequences([text]))\n",
        "    tokens = pad_sequences(tokens, maxlen=maxlen-1)\n",
        "\n",
        "    pred_token = np.argmax(model.predict([tokens], verbose=False), axis=1)[0]\n",
        "    pred_word = tokenizer.index_word[pred_token+1]\n",
        "\n",
        "    text+=\" \"+pred_word\n",
        "    output+=pred_word+\" \"\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "4rqNC06HjgMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_on_epoch(epoch, _):\n",
        "  output = generate()\n",
        "  print('\\nDante dice: \"'+output+'\"')"
      ],
      "metadata": {
        "id": "LjtUYiP1nule"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_callback = LambdaCallback(on_epoch_end=generate_on_epoch)\n",
        "model.fit(X, y, batch_size=128, epochs=100, callbacks=[epoch_callback])"
      ],
      "metadata": {
        "id": "LrkeiGscovot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d37e1449-1e49-4f10-de13-bf5ae5b556b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 7.2586 - accuracy: 0.0391\n",
            "Dante dice: \"che che che che che che che che che che che che che che che che che che che che che che che che che \"\n",
            "797/797 [==============================] - 34s 34ms/step - loss: 7.2586 - accuracy: 0.0391\n",
            "Epoch 2/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.8953 - accuracy: 0.0398\n",
            "Dante dice: \"che che che che che che che che che che che che che che che che che che che che che che che che che \"\n",
            "797/797 [==============================] - 14s 18ms/step - loss: 6.8953 - accuracy: 0.0398\n",
            "Epoch 3/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.7530 - accuracy: 0.0454\n",
            "Dante dice: \"che la ben che l ben che l ben che l ben che l ben che l ben che l ben che l ben che \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 6.7530 - accuracy: 0.0454\n",
            "Epoch 4/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.6446 - accuracy: 0.0518\n",
            "Dante dice: \"l ben che che la ben che che la ben che che la ben che che la ben che che la ben che che la \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 6.6446 - accuracy: 0.0518\n",
            "Epoch 5/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.5558 - accuracy: 0.0564\n",
            "Dante dice: \"la ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 6.5558 - accuracy: 0.0564\n",
            "Epoch 6/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.4699 - accuracy: 0.0614\n",
            "Dante dice: \"che la ben che la ben che la ben che la ben che la ben che la ben che la ben che la ben che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 6.4699 - accuracy: 0.0614\n",
            "Epoch 7/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 6.3876 - accuracy: 0.0678\n",
            "Dante dice: \"nel ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 6.3875 - accuracy: 0.0678\n",
            "Epoch 8/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.3088 - accuracy: 0.0733\n",
            "Dante dice: \"che la sua ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l ben l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 6.3088 - accuracy: 0.0733\n",
            "Epoch 9/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 6.2275 - accuracy: 0.0785\n",
            "Dante dice: \"ch in canto l qual che la sua ben ch in canto l qual che la sua ben ch in canto l qual che la \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 6.2274 - accuracy: 0.0785\n",
            "Epoch 10/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.1362 - accuracy: 0.0854\n",
            "Dante dice: \"mi l qual che la sua altri ch in canto l qual che la sua altri ch in canto l qual che la sua altri \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 6.1362 - accuracy: 0.0854\n",
            "Epoch 11/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 6.0480 - accuracy: 0.0897\n",
            "Dante dice: \"ben l qual che la era l qual che la era l qual che la era l qual che la era l qual che la \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 6.0480 - accuracy: 0.0897\n",
            "Epoch 12/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.9671 - accuracy: 0.0932\n",
            "Dante dice: \"tu ch in canto l qual ch in canto l qual che la tu ch in canto l qual che la tu ch in canto \"\n",
            "797/797 [==============================] - 12s 16ms/step - loss: 5.9671 - accuracy: 0.0932\n",
            "Epoch 13/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.8905 - accuracy: 0.0957\n",
            "Dante dice: \"era ch in tu ch in canto l qual che la tu che la tu che la tu che la tu che la tu che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.8905 - accuracy: 0.0957\n",
            "Epoch 14/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 5.8179 - accuracy: 0.0970\n",
            "Dante dice: \"qual per a a ond in canto l qual per a a a ond in canto l qual per a a a ond in canto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.8182 - accuracy: 0.0970\n",
            "Epoch 15/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 5.7525 - accuracy: 0.0987\n",
            "Dante dice: \"sua altri ch in canto l qual io l sua altri ch in canto l qual io l sua altri ch in canto l qual \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.7526 - accuracy: 0.0987\n",
            "Epoch 16/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 5.6903 - accuracy: 0.1002\n",
            "Dante dice: \"l qual per a a a ond in canto l qual per a a a ond in canto l qual per a a a ond \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.6903 - accuracy: 0.1001\n",
            "Epoch 17/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.6311 - accuracy: 0.1016\n",
            "Dante dice: \"l nel qual ch in quanto ch in canto l qual ch in canto l qual ch in canto l qual ch in canto l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.6311 - accuracy: 0.1016\n",
            "Epoch 18/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.5743 - accuracy: 0.1026\n",
            "Dante dice: \"la tu l qual ch in quanto ch in quanto ch in canto l qual per a son ch in canto l qual per a \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.5743 - accuracy: 0.1026\n",
            "Epoch 19/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.5194 - accuracy: 0.1037\n",
            "Dante dice: \"donna l nel qual ch in canto l qual ch in canto l qual per a son ch in canto l qual per a son \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.5194 - accuracy: 0.1037\n",
            "Epoch 20/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 5.4651 - accuracy: 0.1050\n",
            "Dante dice: \"l nel qual per a son ch in quanto ch in canto l qual per a son ch in quanto ch in canto l qual \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.4652 - accuracy: 0.1050\n",
            "Epoch 21/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 5.4117 - accuracy: 0.1065\n",
            "Dante dice: \"l nel qual per l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.4121 - accuracy: 0.1065\n",
            "Epoch 22/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 5.3611 - accuracy: 0.1080\n",
            "Dante dice: \"l sua poscia l nel qual per l qual per l qual per l qual per l qual per l qual per l qual per \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.3609 - accuracy: 0.1081\n",
            "Epoch 23/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.3088 - accuracy: 0.1092\n",
            "Dante dice: \"non ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.3088 - accuracy: 0.1092\n",
            "Epoch 24/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 5.2603 - accuracy: 0.1096\n",
            "Dante dice: \"l nel qual per l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.2603 - accuracy: 0.1096\n",
            "Epoch 25/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.2128 - accuracy: 0.1112\n",
            "Dante dice: \"di quivi l qual per l qual per l qual per l qual per l qual per l qual per l qual per l qual \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.2128 - accuracy: 0.1112\n",
            "Epoch 26/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 5.1648 - accuracy: 0.1125\n",
            "Dante dice: \"l sua alta l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.1648 - accuracy: 0.1125\n",
            "Epoch 27/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 5.1171 - accuracy: 0.1139\n",
            "Dante dice: \"l nel qual per lor donna l nel qual ch in quanto ch in era ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.1173 - accuracy: 0.1138\n",
            "Epoch 28/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 5.0709 - accuracy: 0.1156\n",
            "Dante dice: \"in canto fora che la era l qual riporterò che la era l qual per a lor prieghe ch in canto fora che la era \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.0714 - accuracy: 0.1156\n",
            "Epoch 29/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 5.0271 - accuracy: 0.1185\n",
            "Dante dice: \"qual ch in quanto ch in quanto ch in canto fora per a lor altri ch in canto fora per a lor altri ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 5.0271 - accuracy: 0.1185\n",
            "Epoch 30/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.9844 - accuracy: 0.1205\n",
            "Dante dice: \"l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.9845 - accuracy: 0.1205\n",
            "Epoch 31/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.9428 - accuracy: 0.1227\n",
            "Dante dice: \"in era l qual ch in quanto ch in quanto ch in canto fora che la era l qual ch in quanto ch in quanto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.9432 - accuracy: 0.1227\n",
            "Epoch 32/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.9064 - accuracy: 0.1247\n",
            "Dante dice: \"l qual folo l nel qual per l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.9064 - accuracy: 0.1247\n",
            "Epoch 33/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.8675 - accuracy: 0.1270\n",
            "Dante dice: \"poi l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.8675 - accuracy: 0.1270\n",
            "Epoch 34/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.8308 - accuracy: 0.1293\n",
            "Dante dice: \"l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.8308 - accuracy: 0.1293\n",
            "Epoch 35/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.7968 - accuracy: 0.1311\n",
            "Dante dice: \"ch in quanto ch in quanto ch in canto fora distingue la era l qual ch in canto fora distingue sì l nel qual ch \"\n",
            "797/797 [==============================] - 11s 14ms/step - loss: 4.7968 - accuracy: 0.1311\n",
            "Epoch 36/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.7622 - accuracy: 0.1338\n",
            "Dante dice: \"l nel qual premerei l veder ch ti pria i rinovelle che ch in canto fora l nel qual ch in quanto ch in quanto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.7618 - accuracy: 0.1339\n",
            "Epoch 37/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.7297 - accuracy: 0.1356\n",
            "Dante dice: \"a fa ch in era ch in canto fora distingue la era ch in canto etterni che la era ch in quanto ch in era \"\n",
            "797/797 [==============================] - 12s 14ms/step - loss: 4.7298 - accuracy: 0.1356\n",
            "Epoch 38/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.6959 - accuracy: 0.1382\n",
            "Dante dice: \"di canto fora turno che la era ch mi appressavan che ch in paladino che non ch in canto l qual per a lui ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.6959 - accuracy: 0.1382\n",
            "Epoch 39/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.6667 - accuracy: 0.1402\n",
            "Dante dice: \"l nel qual ch in quanto ch ti mal strega l nel qual ch in quanto ch ti tra odori petti l nel qual ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.6667 - accuracy: 0.1402\n",
            "Epoch 40/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.6336 - accuracy: 0.1427\n",
            "Dante dice: \"infino di altro l qual ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.6336 - accuracy: 0.1427\n",
            "Epoch 41/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.6054 - accuracy: 0.1455\n",
            "Dante dice: \"per altro conviensi mi perché non bollor nver sì triforme tu lodiam se la una altri ma per a son ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.6055 - accuracy: 0.1455\n",
            "Epoch 42/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.5740 - accuracy: 0.1483\n",
            "Dante dice: \"qual ch solamente per fa ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in \"\n",
            "797/797 [==============================] - 12s 14ms/step - loss: 4.5739 - accuracy: 0.1483\n",
            "Epoch 43/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 4.5457 - accuracy: 0.1511\n",
            "Dante dice: \"che la era ch solamente mi sarà appunta in fia che la era ch in quanto ch in quanto ch in quanto ch in quanto \"\n",
            "797/797 [==============================] - 12s 14ms/step - loss: 4.5461 - accuracy: 0.1511\n",
            "Epoch 44/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.5177 - accuracy: 0.1535\n",
            "Dante dice: \"cor gonne secco affanni che a fa ch solamente la una altri ch in fia commensurar l nel qual sentiranno non voglia l faccia mi \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.5175 - accuracy: 0.1535\n",
            "Epoch 45/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 4.4917 - accuracy: 0.1560\n",
            "Dante dice: \"lo nel qual folo l nel qual sentiranno non perché sospinte cantavano che non perdeo la una altri per la era che la una altri \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.4921 - accuracy: 0.1560\n",
            "Epoch 46/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.4635 - accuracy: 0.1586\n",
            "Dante dice: \"che la una altri trasparere che a lor infino di greco commedia che la era ch ti babillòn l qual per lor acquistò l veder \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.4635 - accuracy: 0.1586\n",
            "Epoch 47/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.4363 - accuracy: 0.1607\n",
            "Dante dice: \"calda seppi che sì albor accrescerà de a poi rapiron l nel qual sentiranno non perché sospinte cantavano che me che la una altri ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.4365 - accuracy: 0.1607\n",
            "Epoch 48/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.4112 - accuracy: 0.1638\n",
            "Dante dice: \"che la era l intorno alloro l nel qual essa che la era l faccia l faccia l qual per a vuol falsificando spargo terrestro \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.4116 - accuracy: 0.1637\n",
            "Epoch 49/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.3852 - accuracy: 0.1670\n",
            "Dante dice: \"tu nasidio non ritrasse non non v mi dire che a calcai ambo la era ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.3851 - accuracy: 0.1671\n",
            "Epoch 50/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.3608 - accuracy: 0.1690\n",
            "Dante dice: \"io l veder ch qua per fialte di l qual per a lui ch in fia che de a poi bergamaschi l sua buone miste \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.3609 - accuracy: 0.1690\n",
            "Epoch 51/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.3336 - accuracy: 0.1719\n",
            "Dante dice: \"se la era ch solamente la abitanti i l intorno mi savere al te le fine che la era l cittadina i che ne la \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.3336 - accuracy: 0.1719\n",
            "Epoch 52/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 4.3098 - accuracy: 0.1743\n",
            "Dante dice: \"elli in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch in quanto ch \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.3105 - accuracy: 0.1742\n",
            "Epoch 53/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.2894 - accuracy: 0.1757\n",
            "Dante dice: \"mi radice diria mi mi giovanetto l qual al sua colore l veder che la una altri ch ti sostegna ilión pur che per fa \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.2896 - accuracy: 0.1757\n",
            "Epoch 54/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 4.2661 - accuracy: 0.1777\n",
            "Dante dice: \"che non perdeo la una altri ch in quanto ch in canto gota la una altri ch in quanto ch in seguir accende mio l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.2667 - accuracy: 0.1777\n",
            "Epoch 55/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.2472 - accuracy: 0.1803\n",
            "Dante dice: \"sé che mostrava che chiamò l vinti l qual chiamate che la stava l faccia liscia parisi dolce luna brollo di altro gota lui patto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.2472 - accuracy: 0.1803\n",
            "Epoch 56/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.2222 - accuracy: 0.1839\n",
            "Dante dice: \"com in era che la una altri per tremesse che serotini che vige che a poi l feroce onde ch sappi le fine che per \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.2222 - accuracy: 0.1839\n",
            "Epoch 57/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.2024 - accuracy: 0.1854\n",
            "Dante dice: \"affama che la una altri trasparere si pria l può che perfetti rabbuffa che a la era ch in fia che la parte l vinti \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.2024 - accuracy: 0.1854\n",
            "Epoch 58/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 4.1800 - accuracy: 0.1871\n",
            "Dante dice: \"in quanto immortale gridaro di a a a lui messa micòl dilette scorno la era che la satisfara non temenza non magre ad venisse che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.1807 - accuracy: 0.1870\n",
            "Epoch 59/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.1626 - accuracy: 0.1892\n",
            "Dante dice: \"dieno che a ulivo altri li ben innalzo io elli in quanto ch mirabil tua bei l qual per fia uditi si tra ed se \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.1626 - accuracy: 0.1892\n",
            "Epoch 60/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.1406 - accuracy: 0.1920\n",
            "Dante dice: \"savorose io compartir cor non biancheggiare che sì forbi come fattor la una anime lungh lor stenda a a lor bello cansarsi l ella grassi \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 4.1402 - accuracy: 0.1921\n",
            "Epoch 61/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.1198 - accuracy: 0.1950\n",
            "Dante dice: \"l nel qual folo le fine inclita quando in fia commensurar l nel qual essa guardavam di belisar grida vidi che la era che la \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.1200 - accuracy: 0.1950\n",
            "Epoch 62/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.0999 - accuracy: 0.1959\n",
            "Dante dice: \"che drizzai che morse non cor lasciar giaciuto che la era costa rota che ne ricchi che me di rotelle a a lor purgatorio lui \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.1002 - accuracy: 0.1958\n",
            "Epoch 63/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 4.0808 - accuracy: 0.1997\n",
            "Dante dice: \"che a tafani punga che in fia che la titone sua dette divenendo l qual al veder che il te che darli vòlto di canto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.0809 - accuracy: 0.1996\n",
            "Epoch 64/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.0625 - accuracy: 0.2012\n",
            "Dante dice: \"arbore forca l qual essa rinova pasturale che la era che la era che la satisfara novo l nel primo ch mi perché così per \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 4.0625 - accuracy: 0.2012\n",
            "Epoch 65/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 4.0441 - accuracy: 0.2030\n",
            "Dante dice: \"umido affibbia la toro riprendendo l qual sentiranno che lai la nvidia a lui non fortunata principati che non il nascose l qual luca glauco \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 4.0442 - accuracy: 0.2030\n",
            "Epoch 66/100\n",
            "793/797 [============================>.] - ETA: 0s - loss: 4.0253 - accuracy: 0.2058\n",
            "Dante dice: \"di canto etterni che la era ch solamente per rame l surgeran onesta che la era l faccia l qual luca purgando a usata non \"\n",
            "797/797 [==============================] - 12s 16ms/step - loss: 4.0257 - accuracy: 0.2057\n",
            "Epoch 67/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 4.0064 - accuracy: 0.2078\n",
            "Dante dice: \"lui elle bende che lucore a poi seminata a poi l intima due quel l qual di son ch cessa che trar l quiete che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 4.0064 - accuracy: 0.2078\n",
            "Epoch 68/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.9893 - accuracy: 0.2099\n",
            "Dante dice: \"l qual per a mia entro per a son ch ti raccerta che tambernicchi che ne sì l vinti con incontrato ti vii cessar sanesi \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9894 - accuracy: 0.2099\n",
            "Epoch 69/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.9709 - accuracy: 0.2131\n",
            "Dante dice: \"l faccia l qual luca già di santo vinto che falsi l faccia l qual luca foro bilancia sarò dilettanze l qual ch sono quello \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9708 - accuracy: 0.2131\n",
            "Epoch 70/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.9587 - accuracy: 0.2140\n",
            "Dante dice: \"cherubini che in fia l faccia che la era che cinta più l qual io l qual io già la madre dispoglia nieghi l nel \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9593 - accuracy: 0.2139\n",
            "Epoch 71/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.9403 - accuracy: 0.2169\n",
            "Dante dice: \"ti suoli fu in fia l qual io di quando ne a lor ardirei si pria le certo valle l nel qual sé ch qua \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9405 - accuracy: 0.2168\n",
            "Epoch 72/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.9223 - accuracy: 0.2187\n",
            "Dante dice: \"nude giovi riguardi l nel qual sentiranno non sternilmi non elette non l intorno con l cammin stola ha mago accolte per fa ch in \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9227 - accuracy: 0.2187\n",
            "Epoch 73/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.9015 - accuracy: 0.2204\n",
            "Dante dice: \"pien con gente scotto che sì sterne l qual per usato sentir per se passando che la proporzione in fallire di l qual per a \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.9015 - accuracy: 0.2204\n",
            "Epoch 74/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.8898 - accuracy: 0.2235\n",
            "Dante dice: \"troppo sensibilmente l nel qual ch in seguir ricompie per la era l faccia l turbarsi che me piccioletta richiuse con devoto la cagne paura \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.8900 - accuracy: 0.2234\n",
            "Epoch 75/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.8719 - accuracy: 0.2241\n",
            "Dante dice: \"l nel qual folo le certo valle l nel qual folo le fine tiemmi eschi l qual luca inchinava di del modena che la quanto \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.8719 - accuracy: 0.2241\n",
            "Epoch 76/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.8543 - accuracy: 0.2281\n",
            "Dante dice: \"l qual sentiranno non sternilmi non a mai ch in quanto ch violenza di gualoppo che noli asopo che porco più di mai discendo a \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.8543 - accuracy: 0.2280\n",
            "Epoch 77/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.8389 - accuracy: 0.2293\n",
            "Dante dice: \"si tutto che adombra di meglio che la era che dubitava che la quanto ch ti grossa di son a la simiglianza ch in fia \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.8389 - accuracy: 0.2293\n",
            "Epoch 78/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.8259 - accuracy: 0.2314\n",
            "Dante dice: \"le matura che non v grattarmi a me che ne sì l ascondeva io l nel qual essa che nviluppata madre fermar continuando cinquecento facce \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.8257 - accuracy: 0.2314\n",
            "Epoch 79/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.8089 - accuracy: 0.2331\n",
            "Dante dice: \"orto l figurato l banco mi cadde l faccia l turbarsi che ipocràte disciolta sé di poi l quiete di aggiusta che la era ch \"\n",
            "797/797 [==============================] - 12s 16ms/step - loss: 3.8089 - accuracy: 0.2331\n",
            "Epoch 80/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.7935 - accuracy: 0.2357\n",
            "Dante dice: \"mostrata mi sentir non germinato quando ch ti quell corse vedere di me che un buon trarria si tutto iesù navarra ardor andavam stral che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7935 - accuracy: 0.2357\n",
            "Epoch 81/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.7792 - accuracy: 0.2377\n",
            "Dante dice: \"coram poi trarrotti l qual non privilegio move mio tebano pece si mentre l qual fu la penitenza pietra recenti che la una altri loglio \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7792 - accuracy: 0.2377\n",
            "Epoch 82/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.7663 - accuracy: 0.2394\n",
            "Dante dice: \"che non cor dandole spargo adona che non sospetto si dannosa sì l qual per sì adempierà a me di svia pregassi di gente rapiron \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7663 - accuracy: 0.2394\n",
            "Epoch 83/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.7507 - accuracy: 0.2415\n",
            "Dante dice: \"raggiare trascende aragne l veder con a lor tornate disiar sguardo marca si colori tu dotta imagine l padre l qual lo veder ne sì \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7510 - accuracy: 0.2414\n",
            "Epoch 84/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.7354 - accuracy: 0.2427\n",
            "Dante dice: \"siena l divenuti animal a lor mensa i creatore in templo l qual luca il fasciati credo li speran l fiere che de a a \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7354 - accuracy: 0.2427\n",
            "Epoch 85/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.7217 - accuracy: 0.2448\n",
            "Dante dice: \"libicocco superbe novitadi l intima due speso le certo che italica menzogna vapor abisso necessità che li ben gurge s ritrasse che la alto ncontra \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7217 - accuracy: 0.2448\n",
            "Epoch 86/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.7090 - accuracy: 0.2473\n",
            "Dante dice: \"ben deus pietra pozzo maschio disiro portato calde l qual luca per la quanto ch fommi stingue l qual luca per pesci l padre è \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7094 - accuracy: 0.2473\n",
            "Epoch 87/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.7032 - accuracy: 0.2485\n",
            "Dante dice: \"ingannò si tre diserra che la era che ch prieghi discarchi che non ch in fia che non montagna lieti noia di santo vinto per \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.7032 - accuracy: 0.2485\n",
            "Epoch 88/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.6831 - accuracy: 0.2505\n",
            "Dante dice: \"mi piombo l vigor l qual sentiranno non monti ragiona frusto piangevan mi guancia che la una sobranza aggrada di lor grazie venivan levate che \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6830 - accuracy: 0.2505\n",
            "Epoch 89/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.6672 - accuracy: 0.2534\n",
            "Dante dice: \"l qual io di quivi che non ch di infino di avaro mieto che per a vuol eccelso argo io per ciel piovve scuola l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6672 - accuracy: 0.2534\n",
            "Epoch 90/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.6565 - accuracy: 0.2548\n",
            "Dante dice: \"muro che per fa ch in intra fui vai l mi ammirazione m ti foss in poi l ascondeva che a lor nol nuda squilla \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6568 - accuracy: 0.2548\n",
            "Epoch 91/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.6436 - accuracy: 0.2550\n",
            "Dante dice: \"riedi ne a fa ch in quanto ch in fia commensurar l dolce non l qual ribatter che femmina surger scorno per ne sì augelli \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6436 - accuracy: 0.2550\n",
            "Epoch 92/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.6300 - accuracy: 0.2585\n",
            "Dante dice: \"veggio l nel qual per a era ch ti venivan donno l qual che uopo l qual al duca bella menommi in iddio non l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6297 - accuracy: 0.2584\n",
            "Epoch 93/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.6133 - accuracy: 0.2607\n",
            "Dante dice: \"da poi spessi più ti tornò si séguita a a a ed se ne a fratel vaneggia mio mi giovanetto l qual io di picciol \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6146 - accuracy: 0.2606\n",
            "Epoch 94/100\n",
            "797/797 [==============================] - ETA: 0s - loss: 3.6031 - accuracy: 0.2618\n",
            "Dante dice: \"l quiete che diedi al sua ond qua abisso l quiete io l qual al fronda descripto l qual al spirto sua faccendo vidi regge \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.6031 - accuracy: 0.2618\n",
            "Epoch 95/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.5944 - accuracy: 0.2629\n",
            "Dante dice: \"io tal etternale che non ch in mai a a lagrimando fu circular destro arca che non per sì le fine inclita duce a a \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.5942 - accuracy: 0.2629\n",
            "Epoch 96/100\n",
            "796/797 [============================>.] - ETA: 0s - loss: 3.5848 - accuracy: 0.2644\n",
            "Dante dice: \"che del sua vid in vostra artista rifiuto l primo sospirando s fronde arrestin ripe l sanguinando che se ne la era digiuno che alì \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 3.5848 - accuracy: 0.2644\n",
            "Epoch 97/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.5735 - accuracy: 0.2673\n",
            "Dante dice: \"mostrata mi ruote io con sì l convienmi fu mia spalle di a a sì che ch in fia l qual sentiranno non perché distar \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.5735 - accuracy: 0.2673\n",
            "Epoch 98/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.5608 - accuracy: 0.2684\n",
            "Dante dice: \"non castrocaro che viso che appostolico nacquero mio fronde s fate vista che per fa risposta lungo a mia pensando per riva s mutar saranno \"\n",
            "797/797 [==============================] - 13s 16ms/step - loss: 3.5615 - accuracy: 0.2683\n",
            "Epoch 99/100\n",
            "794/797 [============================>.] - ETA: 0s - loss: 3.5457 - accuracy: 0.2697\n",
            "Dante dice: \"cor gonne secco peli l qual sé non ch di gente l figli mio perché de a sigieri l qual d prima saran più plaude \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.5461 - accuracy: 0.2697\n",
            "Epoch 100/100\n",
            "795/797 [============================>.] - ETA: 0s - loss: 3.5378 - accuracy: 0.2722\n",
            "Dante dice: \"com però di quando chiostro per lussuria più compartir cor ché non castrocaro si proceder di fiordaliso che la era digiuno pasce che sì l \"\n",
            "797/797 [==============================] - 12s 15ms/step - loss: 3.5375 - accuracy: 0.2722\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa9103d16c0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ciao come stai\"\n",
        "\n",
        "tokens = np.array(tokenizer.texts_to_sequences([text]))\n",
        "tokens = pad_sequences(tokens, maxlen=maxlen-1)\n",
        "\n",
        "pred_proba = model.predict([tokens], verbose=False)\n",
        "pred_token = np.argmax(pred_proba, axis=1)[0]\n",
        "print(pred_proba)\n",
        "pred_word = tokenizer.index_word[pred_token]\n"
      ],
      "metadata": {
        "id": "8nE42dL-sX67"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}